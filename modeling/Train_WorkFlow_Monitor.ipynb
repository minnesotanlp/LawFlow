{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set-up"
      ],
      "metadata": {
        "id": "t9mJvRhEBMh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch -qqq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aen3A8xHF2Ub",
        "outputId": "c7876767-a2dc-4c5f-a886-7abd95407b45",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nw7gjwhM9cXv",
        "outputId": "dfda8c40-5f67-48d2-a436-58f0e218883b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scenario_11 = \"\"\"Title: Three-Person Coffee Truck with Entity Formation Contingency\n",
        "Context:\n",
        "Three friends, A, B, and C, want to form a coffee shop out of a food trailer that A purchased while the three were college roommates. They had informally used the trailer to sell coffee products on campus, but would like to see if they could form a real business. The key to their popularity has been A’s importation of Hawaiian coffee beans, which help the trio brew delicious coffee drinks but has proven to be an expensive business decision. If they form an entity, they might want to see whether they could have investors supply some extra money to help them cover the cost of importing the beans. They would plan on giving the investors some kind of profit interest in the business in exchange for their help, but aren’t too familiar with how that would work.\n",
        "\n",
        "In addition, this venture has largely been A’s project. B and C aren’t quite as invested, as they have more time-consuming careers of their own. The group’s other friends, D and E, however, have kept in touch with A and have expressed interest in joining the business in place of B and C. B and C might be open to this as well, but will need some time to think. A must also later decide if he wants anyone involved with the business to be able to come and go as they please, or if he wants a firmer commitment from anyone involved with the truck (either B and C or D and E) to devote more of their time and resources to it.\n",
        "\n",
        "Details:\n",
        "Three-person\n",
        "Sale of Goods\n",
        "Personal Property\n",
        "Entity Selection\n",
        "\n",
        "Complexity Tags:\n",
        "1. Memo needed\n",
        "2. Diverging Interests of Clients\n",
        "8. Multiple Sessions Needed for Entity Choice\n",
        "\n",
        "Complexity: Medium\n",
        "\"\"\"\n",
        "\n",
        "scenario_12 = \"\"\"Title: One Person Nonprofit Running Club\n",
        "Context:\n",
        "E wants to form an organization that will encourage people in his neighborhood to embrace the benefits of physical fitness and running, as part of a larger effort to promote general well-being. Titled “Run Minnesota,” E’s vision is to have groups of people regularly meet to run, and hopefully grow enough to organize larger events—5ks, 10ks, etc.—the registration proceeds of which will go to either investing in local initiatives surrounding health and fitness, or to support cancer research at in-state institutions. Aside from E’s own capital, the organization’s initial funding is planned to be provided from contributions from community members, and any work at future events will be done by volunteers. E does not seek to profit off of this endeavor, and does not want to report additional income from any registration proceeds or donations—or risk not reporting it—on his personal tax return. If the business incorporates, E would seek to add F, G, and H to its board of directors. If the organization grows as planned, E would seek to hire a handful of full- or part-time employees to handle marketing, event organization, and other administrative work.\n",
        "\n",
        "Details:\n",
        "One Person\n",
        "Business Growth\n",
        "No Profit Motive\n",
        "\n",
        "Complexity Tags:\n",
        "1. Memo Needed\n",
        "\"\"\"\n",
        "\n",
        "scenario_13 = \"\"\"Title: One Person Ice Cream Maker\n",
        "Context:\n",
        "E has recently developed a process for making premium homemade ice cream with locally-sourced ingredients. The result has been a hit: E’s flavors are wide-ranging, unique, and high-quality. E has started by sharing the products with neighbors, who have suggested that he sell it for profit. E has not yet done so, but might be interested. He is wondering how to best proceed by beginning with local sales and going from there.\n",
        "\n",
        "Details:\n",
        "One person\n",
        "Inexperienced client\n",
        "\n",
        "Issues:\n",
        "Formation\n",
        "Branding\n",
        "IP\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "scenario_14 = \"\"\"Title: Fishing Education\n",
        "Context:\n",
        "A and B are each avid anglers and seek to grow the sport within their area, which is largely urban. They seek to teach fishing skills—ranging from basic to advanced—to both children and adults, through events held at parks, lakes, and rivers nearby. They envision weekly or monthly workshops where they educate participants on a particular skill—casting, knot tying, fish landing with a net, and more. Signup for the workshops is free. A and B encourage participants to bring their own fishing gear, but plan on contracting with a local sporting goods store to purchase bulk orders of tackle at a discounted rate. Because of that, they have decided to explore forming a business entity.\n",
        "\n",
        "Neither A nor B are particularly familiar with small business structure or ownership, and don’t seek to profit from the business. They would like, however, to minimize any formalities associated with owning a business. In addition, they would like to raffle off fishing apparel at some of the workshops, and are ok using their own money to buy these items for the first few instances. If their workshops are popular and they consistently have high attendance, they would like to borrow money or obtain outside funding to keep this practice up.\n",
        "\n",
        "Overall, they want to learn more about the function of any documents used to start the business, and potentially review anything that’s written for them before they officially get to work.\n",
        "\n",
        "Details:\n",
        "Three Person\n",
        "Low Liability\n",
        "Informal Structure\n",
        "\n",
        "Complexity Tags:\n",
        "3. Follow-up for Operating Agreement Review\n",
        "7. Inexperienced Client\n",
        "\"\"\"\n",
        "\n",
        "scenario_15 = \"\"\"Title: Lake Bed and Breakfast\n",
        "Context:\n",
        "M and A want to operate a bed and breakfast on the lake where they keep a cabin – just outside a small town in the northern, rural part of their home state. They intend to run a relatively small operation: the building they have picked out is a four bedroom house that can accommodate up to ten people comfortably. It is in relatively good shape, but would benefit from a handful of basic renovations. M and A will cook breakfasts, provide housekeeping services, and lead hikes for guests in the surrounding area. They will also provide kayaks, stand up paddleboards, and jet skis for rent, all of which are personally owned by the couple. They have a sufficient (i.e. covering everything) liability waiver in place which guests agree to upon booking their stay. Per an informal agreement, M and A have also received some funding from the nearby town’s chamber of commerce in exchange for recommending other local businesses to their guests. They’re interested in forming a business to separate their personal assets from that of the business.\n",
        "\n",
        "In addition, they’d like to pass the business to their three children (ownership divided equally among them), and want to add them to the business now, each with ⅙ ownership (M and A each holding a 25% ownership). They would also like a provision in any operating document to specify that, should anyone seek to sell their ownership interest, the remaining members must get the first offer or otherwise unanimously consent in writing to the transfer.\n",
        "\n",
        "Details:\n",
        "Two Person\n",
        "Services\n",
        "Varying Liability\n",
        "Transfer of Business\n",
        "\n",
        "Issues:\n",
        "Entity Formation\n",
        "Addition of Members\n",
        "Restrictions on Interest Transfer\n",
        "\n",
        "Complexity Tags:\n",
        "1. Memo needed\n",
        "2. Diverging interests of clients\n",
        "\"\"\"\n",
        "\n",
        "scenario_16 = \"\"\"Title: Biotech Group Seeking Funding\n",
        "Context:\n",
        "A and B have been co-developing an organic, temperature-regulating soil that—when mixed with naturally-occurring soil—helps keep planted flowers cool even in the hottest of temperatures. A and B have created the chemical composition themselves, which holds water at a more constant rate than other soils regardless of temperature. A and B have had excellent results growing their own plants with the soil, but need additional funding to produce an amount that’s large enough to be tested on a greater scale—and which would ultimately help indicate whether they could form a viable business. A and B’s friend C has an eye for promising business ideas. She knows the two have a strong work ethic and believes that the soil will be a success if the two can consistently produce enough of it to meet demands of early testers. C is willing to invest $2M for a 30% ownership interest, which A and B agree to. If all goes well, the three would like to sell the soil’s chemical composition to a biotech company. A and B stay current with the industry and know that they have made a quiet breakthrough with the soil, which is a sought-after product by a number of companies.\n",
        "\n",
        "Details:\n",
        "Three person\n",
        "Outside Funding\n",
        "Business Growth\n",
        "Intellectual Property\n",
        "\n",
        "Complexity Tags:\n",
        "1. Memo needed\n",
        "5. Referral to other lawyer\"\"\"\n",
        "\n",
        "scenario_17 = \"\"\"Title: Fishing Education\n",
        "Context:\n",
        "A and B are each avid anglers and seek to grow the sport within their area, which is largely urban. They seek to teach fishing skills—ranging from basic to advanced—to both children and adults, through events held at parks, lakes, and rivers nearby. They envision weekly or monthly workshops where they educate participants on a particular skill—casting, knot tying, fish landing with a net, and more. Signup for the workshops is free. A and B encourage participants to bring their own fishing gear, but plan on contracting with a local sporting goods store to purchase bulk orders of tackle at a discounted rate. Because of that, they have decided to explore forming a business entity.\n",
        "\n",
        "Neither A nor B are particularly familiar with small business structure or ownership, and don’t seek to profit from the business. They would like, however, to minimize any formalities associated with owning a business. In addition, they would like to raffle off fishing apparel at some of the workshops, and are ok using their own money to buy these items for the first few instances. If their workshops are popular and they consistently have high attendance, they would like to borrow money or obtain outside funding to keep this practice up.\n",
        "\n",
        "Overall, they want to learn more about the function of any documents used to start the business, and potentially review anything that’s written for them before they officially get to work.\n",
        "\n",
        "Details:\n",
        "Three Person\n",
        "Low Liability\n",
        "Informal Structure\n",
        "\n",
        "Complexity Tags:\n",
        "3. Follow-up for Operating Agreement Review\n",
        "7. Inexperienced Client\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "scenario_18 = \"\"\"Title: Shared Workspace and Kitchen\n",
        "Context:\n",
        "P is looking to bring together other businesses in his community by offering a space that functions as both a commercial kitchen and shared workspace, which can be leased by individuals or other entities. P has already formed an LLC for this purpose. The leases may be by the hour or by the day, and can be for the kitchen, spots in the workspace, or for the entire property. To minimize out-of-pocket expenses, P decides to obtain financing from a local bank for the necessary remodeling. In addition to the normal rentals, P has two other potential uses associated with the building. One is a regularly-occurring food truck fair that will feature local, newly-formed food trucks. It will take place on the building’s property, in its parking lot. The second is a temporary restaurant featuring one of P’s former business partners (B) who has become a chef. The restaurant will have the exclusive use of the space for ten weeks of the subsequent summer, and will be a collaborative effort between the two entities. P will be involved as well, as he and B had originally met while working together in another restaurant.\n",
        "\n",
        "Details:\n",
        "One Person\n",
        "Lease agreement needed\n",
        "\n",
        "Complexity Tags:\n",
        "6. Well-prepared client\n",
        "\"\"\"\n",
        "\n",
        "scenario_19 = \"\"\"Title: Refurbishing Hockey Equipment\n",
        "Context:\n",
        "L accepts used hockey equipment—generally, skates and sticks—and repairs it, sometimes to give back to those who donate it, and other times for resale, if the donating party has no further use for it. The work is mostly done in his home, and varies based on how much equipment he has at a given time. He’s considering implementing the option of selling the resale equipment to a local hockey equipment store, mostly depending on if he keeps getting a supply of broken sticks—the piece of equipment most common on the resale market. Though buyers at these stores are aware of the potential defects of a refurbished hockey stick, the stores selling them generally provide no warranty on them, effectively relieving them of liability. L is confident—and correct—that there are no huge liability risks associated with selling refurbished sticks, but might want some protection—as well as a more official entity—to do business with the stores, and the consumers he sells to on the side.\n",
        "\"\"\"\n",
        "\n",
        "scenario_20 = \"\"\"Title: Doctors and Administrative Person Forming New Entity\n",
        "A, B, and C have all worked together at a health clinic in the Twin Cities for the past 11 years. A and B are both physicians who have client relationships that would follow them from the current clinic to the one they are creating. Even though they will not be able to directly contact the clients from their current practice due to a non-compete agreement, they are well known and respected in the community and expect that many clients will follow them without proactive contact. C is an administrative professional who has practically run the current practice for the last 20 years and will be vital to the day-to-day operations of the new entity. C will be contributing all of the labor to running the new entity, including hiring support staff, scheduling appointments for the doctors, etc. The three have identified a suitable location for the new practice and may either purchase or lease it long-term depending on how the negotiations go. During the conversation, it should become clear that C expects an equal share of the new entity and is also worried about having decision-making power after formation. C does not have as much money to contribute as the doctors do and will be contributing mostly labor. A and B are somewhat dismissive of C’s value and expect to be “running the show” themselves because of their extensive training as doctors, etc. They find C indispensable, but not necessarily worthy of equal ownership in the new entity.\n",
        "\n",
        "Details:\n",
        "Three-person\n",
        "Conflict between them\n",
        "Unequal financial / labor investments\n",
        "\n",
        "Complexity Tags:\n",
        "1. Memo needed\n",
        "2. Diverging interests of clients (Separate lawyers needed)\n",
        "3. Legal ethics - Should these lawyers represent the entity, one or more of the parties, etc.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "PgX6CFlXQZeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scenarios = []\n",
        "\n",
        "for i in range(11, 21):\n",
        "    var_name = f\"scenario_{i}\"\n",
        "    if var_name in globals():\n",
        "        scenarios.append(globals()[var_name])\n",
        "\n",
        "plan = '''1. Gather basic information, discover any underlying complexities\n",
        "    1.1 Ask Default Questions\n",
        "        1.1.1 Take Notes\n",
        "    1.2 Identify potential complications/follow-up questions\n",
        "        1.2.1 Ask follow-up questions\n",
        "    1.3 Identify gaps in knowledge\n",
        "        1.3.1 Search within appropriate realm of resources\n",
        "        1.3.2 Consult colleagues and obtain feedback\n",
        "\n",
        "2. Decide on recommendation to client(s), file forms\n",
        "    2.1 Think about recommendations\n",
        "        2.1.1 Consider counter-arguments/pros and cons\n",
        "    2.2 Identify most important considerations / Decide whether open/shut\n",
        "        2.2.1 Identify whether you can reasonably represent interests of all clients in this case\n",
        "        2.2.2 Communicate with clients if needed\n",
        "    2.3 Determine if you're doing business out of state (will need to file for each state)\n",
        "        2.3.1 Search for relevant info about determining state jx\n",
        "            2.3.1.1 Ask follow-up questions to client if needed\n",
        "        2.3.2 Consult Secretary of State business filling resources (or similar) in relevant jx\n",
        "        2.3.3 File forms personally\n",
        "        2.3.4 Meet with client to file forms\n",
        "        2.3.5 Write memo to client about how to file forms\n",
        "\n",
        "3. Send memo to client\n",
        "    3.1 Write memo\n",
        "        3.1.1 Obtain feedback from colleagues\n",
        "            3.1.1.1 Revise memo\n",
        "        3.1.2 Identify gaps in knowledge (#3)\n",
        "            3.1.2.1 Search within appropriate realm of resources\n",
        "\n",
        "4. Write an Operating Agreement\n",
        "    4.1 Search available template docs\n",
        "        4.1.1 Edit selected template document to create operating agreement\n",
        "            4.1.1.1 Obtain feedback from colleagues\n",
        "                4.1.1.1.1 Revise operating agreement\n",
        "            4.1.1.2 Compare with past agreements/documents used\n",
        "        4.1.2 Identify applicable precedents\n",
        "            4.1.2.1 Determine best (most well-crafted, most precise) and most relevant resources\n",
        "            4.1.2.2 Identify various clauses, provisions that will be useful\n",
        "\n",
        "5. Address Tax Treatment of Entity\n",
        "    5.1 Ask default tax questions of client\n",
        "    5.2 Ask default tax questions of entity\n",
        "    5.3 Identify gaps in knowledge (#5)\n",
        "    5.4 Search within appropriate realm of resources\n",
        "    5.5 Decide whether open/shut\n",
        "        5.5.1 Advise on best entity form\n",
        "        5.5.2 Refer out to tax professional if necessary\n",
        "'''"
      ],
      "metadata": {
        "id": "jRrq-uSIAiob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_executions, human_executions = [], []\n",
        "for i in range(11, 21):\n",
        "  with open(f\"scenario_{i}_steps.json\", \"r\") as f:\n",
        "      llm_executions.append(json.load(f))\n",
        "  with open(f\"scenario_{i}_steps_human.json\", \"r\") as f:\n",
        "      human_executions.append(json.load(f))\n",
        "\n",
        "# train_data = prepare_classifier_data(scenarios, human_executions, llm_executions, plan)\n",
        "\n",
        "# Print first few\n",
        "# for ex in train_data[:5]:\n",
        "#     print(json.dumps(ex, indent=2))\n"
      ],
      "metadata": {
        "id": "Inxnkk0f3drW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def summarize_training_data(train_data):\n",
        "    \"\"\"\n",
        "    Prints summary stats for the training data:\n",
        "Total examples\n",
        "Count of human and LLM instances\n",
        "    \"\"\"\n",
        "    label_counter = Counter(ex[\"label\"] for ex in train_data)\n",
        "\n",
        "    total = len(train_data)\n",
        "    human = label_counter.get(1, 0)\n",
        "    llm = label_counter.get(0, 0)\n",
        "\n",
        "    print(\"=== Training Data Summary ===\")\n",
        "    print(f\"Total instances: {total}\")\n",
        "    print(f\"Human CoT (label=1): {human}\")\n",
        "    print(f\"LLM CoT (label=0): {llm}\")\n",
        "    print(f\"Human %: {100 * human / total:.2f}%, LLM %: {100 * llm / total:.2f}%\")\n",
        "\n",
        "# Usage\n",
        "summarize_training_data(train_data)"
      ],
      "metadata": {
        "id": "4HVTa6GELhvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Llama based Classifier"
      ],
      "metadata": {
        "id": "tRhkeB3u8xL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "Y545OZxQI8dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "llm_executions, human_executions = [], []\n",
        "\n",
        "# Load and modify data\n",
        "for i in range(11, 21):\n",
        "    # Load LLM sequence\n",
        "    with open(f\"scenario_{i}_steps.json\", \"r\") as f:\n",
        "        llm_seq = json.load(f)\n",
        "        # Replace 'END' with '<END>' if present\n",
        "        llm_seq = [\"<START>\"] + [s if s != \"END\" else \"<END>\" for s in llm_seq]  # assuming \"END\" is the exact string\n",
        "        if llm_seq[-1] != \"<END>\":\n",
        "            llm_seq.append(\"<END>\")\n",
        "        llm_executions.append(llm_seq)\n",
        "\n",
        "for i in range(11, 21):\n",
        "    # Load human sequence\n",
        "    with open(f\"scenario_{i}_steps_human.json\", \"r\") as f:\n",
        "        human_seq = json.load(f)\n",
        "        if human_seq[0] != \"<START>\":\n",
        "            human_seq = [\"<START>\"] + human_seq\n",
        "        if human_seq[-1] != \"<END>\":\n",
        "            human_seq = human_seq + [\"<END>\"]\n",
        "        human_executions.append(human_seq)\n",
        "\n",
        "# Remove test examples from human_executions\n",
        "human_test = []\n",
        "human_test.append(human_executions.pop(9))\n",
        "human_test.append(human_executions.pop(8))\n",
        "human_test.reverse()  # restore original order\n",
        "\n",
        "# Sanity check\n",
        "print(f\"Total LLM executions: {len(llm_executions)}\")\n",
        "print(f\"Total remaining human executions: {len(human_executions)}\")\n",
        "print(f\"Total human_test executions: {len(human_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdkdGxqUmpZb",
        "outputId": "5e84c4d4-a879-4d77-949e-b1b4c5e5dbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total LLM executions: 10\n",
            "Total remaining human executions: 8\n",
            "Total human_test executions: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "sZdHfKleLG1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login --relogin"
      ],
      "metadata": {
        "id": "dtkPml1zFN5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "# Make sure padding token is set\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# 1. Preprocess into joined text strings (causal modeling)\n",
        "texts = []\n",
        "for steps in human_executions:\n",
        "    texts.append(\" \".join(steps))\n",
        "\n",
        "# 2. Tokenize with truncation\n",
        "max_length = 256\n",
        "tokenized = tokenizer(\n",
        "    texts,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=max_length,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# 3. Create labels for causal LM\n",
        "labels = tokenized[\"input_ids\"].clone()\n",
        "labels[labels == tokenizer.pad_token_id] = -100  # Mask padding in loss\n",
        "\n",
        "# 4. Custom dataset\n",
        "class CausalDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
        "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
        "            \"labels\": self.labels[idx]\n",
        "        }\n",
        "\n",
        "dataset = CausalDataset(tokenized, labels)\n",
        "wandb.init(project=\"ExpertBench\", name=\"workflow-monitor-3\")\n",
        "\n",
        "# 5. Data collator for causal LM\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # causal, not masked language modeling\n",
        ")\n",
        "\n",
        "# 6. Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./models/outputs_1\",\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size = 2,\n",
        "    num_train_epochs=12,\n",
        "    weight_decay=0.01,\n",
        "    max_grad_norm=2,\n",
        "    logging_steps=1,\n",
        "    report_to=\"wandb\",\n",
        ")\n",
        "\n",
        "\n",
        "# 7. Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# 8. Train\n",
        "trainer.train()\n",
        "\n",
        "# 9. Save model\n",
        "model.save_pretrained(\"./models/llama_human_1\")\n",
        "tokenizer.save_pretrained(\"./models/llama_human_1_tokenizer\")\n"
      ],
      "metadata": {
        "id": "O9N-2n8xfRh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "u-PCG2mrVc7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Average Perplexity Overall"
      ],
      "metadata": {
        "id": "8R-Z6yGUwsx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "def compute_perplexity_local(model, tokenizer, texts, max_length=512):\n",
        "    model.eval()\n",
        "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    ppl_list = []\n",
        "\n",
        "    for text in texts:\n",
        "        encodings = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
        "        input_ids = encodings[\"input_ids\"].to(model.device)\n",
        "        attention_mask = encodings[\"attention_mask\"].to(model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "            loss = outputs.loss\n",
        "            perplexity = torch.exp(loss).item()\n",
        "            ppl_list.append(perplexity)\n",
        "\n",
        "    return ppl_list\n"
      ],
      "metadata": {
        "id": "EJ-tscO8SZme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stepwise conditional Prob"
      ],
      "metadata": {
        "id": "I1jAtxCtw5gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "def compute_log_likelihood(model, tokenizer, text, max_length=512):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
        "    input_ids = inputs[\"input_ids\"].to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, labels=input_ids)\n",
        "    avg_neg_log_prob = outputs.loss.item()\n",
        "    total_tokens = input_ids.size(1)\n",
        "    total_log_likelihood = -avg_neg_log_prob * total_tokens\n",
        "    return total_log_likelihood, total_tokens\n",
        "\n",
        "def compute_stepwise_conditional_perplexity(model, tokenizer, step_list, max_length=512):\n",
        "    \"\"\"\n",
        "    For each step, compute the conditional perplexity of that step given all previous steps as context.\n",
        "    The first step is evaluated standalone.\n",
        "    \"\"\"\n",
        "    device = model.device\n",
        "    model.eval()\n",
        "    results = []\n",
        "\n",
        "    for i in range(len(step_list)):\n",
        "        target = step_list[i]\n",
        "        if not target.strip():\n",
        "            results.append((target, float(\"nan\")))\n",
        "            continue\n",
        "        if i == 0:\n",
        "            # No context: evaluate PPL of the step alone\n",
        "            cond_text = target\n",
        "            LL_context, len_context = 0.0, 0\n",
        "        else:\n",
        "            context = \"\\n\".join(step_list[:i])\n",
        "            cond_text = context + \"\\n\" + target\n",
        "            LL_context, len_context = compute_log_likelihood(model, tokenizer, context, max_length)\n",
        "\n",
        "        LL_full, len_full = compute_log_likelihood(model, tokenizer, cond_text, max_length)\n",
        "        delta_LL = LL_full - LL_context\n",
        "        new_tokens = len_full - len_context\n",
        "        print(f'new_tokens: {new_tokens}')\n",
        "        print(f'delta_LL: {delta_LL}')\n",
        "\n",
        "        if new_tokens > 0:\n",
        "            avg_nll = -delta_LL / new_tokens\n",
        "            cond_ppl = math.exp(avg_nll)\n",
        "        else:\n",
        "            cond_ppl = float(\"nan\")\n",
        "\n",
        "        results.append((target, cond_ppl))\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "GFZ0Rqy81gBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flag_high_perplexity_steps(model, tokenizer, step_list, max_length=512, threshold=10.0, context_window=2):\n",
        "    \"\"\"\n",
        "    Identifies and returns steps whose conditional perplexity exceeds the threshold.\n",
        "    Shows only the last `context_window` steps for context.\n",
        "\n",
        "    Returns:\n",
        "        A list of dictionaries: {\n",
        "            \"step_index\": int,\n",
        "            \"step_text\": str,\n",
        "            \"perplexity\": float,\n",
        "            \"context\": str\n",
        "        }\n",
        "    \"\"\"\n",
        "    device = model.device\n",
        "    model.eval()\n",
        "    flagged_steps = []\n",
        "\n",
        "    for i in range(len(step_list)):\n",
        "        target = step_list[i]\n",
        "        if not target.strip():\n",
        "            continue\n",
        "\n",
        "        # Context: Only include the last `context_window` steps\n",
        "        if i == 0:\n",
        "            context = \"\"\n",
        "            cond_text = target\n",
        "            LL_context, len_context = 0.0, 0\n",
        "        else:\n",
        "            context_steps = step_list[max(0, i - context_window):i]  # Last `context_window` steps\n",
        "            context = \"\\n\".join(context_steps)\n",
        "            cond_text = context + \"\\n\" + target\n",
        "            LL_context, len_context = compute_log_likelihood(model, tokenizer, context, max_length)\n",
        "\n",
        "        LL_full, len_full = compute_log_likelihood(model, tokenizer, cond_text, max_length)\n",
        "        delta_LL = LL_full - LL_context\n",
        "        new_tokens = len_full - len_context\n",
        "\n",
        "        if new_tokens > 0:\n",
        "            avg_nll = -delta_LL / new_tokens\n",
        "            cond_ppl = math.exp(avg_nll)\n",
        "        else:\n",
        "            cond_ppl = float(\"nan\")\n",
        "\n",
        "        # Flag if perplexity exceeds the threshold\n",
        "        if cond_ppl > threshold:\n",
        "            flagged_steps.append({\n",
        "                \"step_index\": i,\n",
        "                \"step_text\": target,\n",
        "                \"perplexity\": cond_ppl,\n",
        "                \"context\": context\n",
        "            })\n",
        "\n",
        "    return flagged_steps\n"
      ],
      "metadata": {
        "id": "Cle97FDYYPCm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}